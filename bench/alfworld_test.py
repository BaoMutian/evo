#!/usr/bin/env python
"""
ALFWorld LLM Agent æµ‹è¯•è„šæœ¬

æµ‹è¯•LLMåœ¨ALFWorldå®¶å±…ä»»åŠ¡ç¯å¢ƒä¸­çš„å¤šè½®äº¤äº’èƒ½åŠ›ã€‚
é‡‡ç”¨ReActé£æ ¼çš„promptï¼Œè®©LLMæ ¹æ®ç¯å¢ƒè§‚å¯Ÿè¿›è¡Œæ€è€ƒå¹¶é€‰æ‹©åŠ¨ä½œã€‚

ä½¿ç”¨æ–¹æ³•:
    1. ç¡®ä¿å®‰è£…ä¾èµ–: cd alfworld && pip install -e .
    2. è®¾ç½®ç¯å¢ƒå˜é‡: export ALFWORLD_DATA=/home/bmt/evo/bench/alfworld/data
    3. è¿è¡Œ: python alfworld_test.py

è®¾å®šSEEDå’ŒNUM_GAMESåç¡®ä¿ç»“æœå¯å¤ç°ã€‚
"""

from llms_api.call_openrouter_llm import call_openrouter_llm_with_retry
from alfworld.agents.environment.alfred_tw_env import AlfredDemangler, AlfredInfos, AlfredExpert, AlfredExpertType
import textworld.gym
import textworld
import yaml
import os
import sys
import json
import random
import re
from typing import Optional, Tuple, List, Dict
from datetime import datetime
from dotenv import load_dotenv

# è®¾ç½®ç¯å¢ƒå˜é‡ (å¿…é¡»åœ¨å¯¼å…¥alfworldä¹‹å‰)
load_dotenv()
ALFWORLD_DATA = os.getenv("ALFWORLD_DATA")
sys.path.insert(0, ALFWORLD_DATA)


# å¯¼å…¥LLMè°ƒç”¨æ¨¡å—

# ============= é…ç½® =============
DEFAULT_MODEL = "qwen/qwen3-30b-a3b-instruct-2507"  # é»˜è®¤æµ‹è¯•çš„æ¨¡å‹
MAX_STEPS = 30  # æ¯ä¸ªä»»åŠ¡çš„æœ€å¤§æ­¥æ•°
NUM_GAMES = 5  # æµ‹è¯•çš„æ¸¸æˆæ•°é‡
TEMPERATURE = 0.3  # LLMæ¸©åº¦å‚æ•° (è¾ƒä½æ¸©åº¦ä½¿è¾“å‡ºæ›´ç¡®å®š)
DEFAULT_SEED = 42  # é»˜è®¤éšæœºç§å­ (ç”¨äºå¯å¤ç°çš„æµ‹è¯•ï¼Œè®¾ä¸ºNoneåˆ™éšæœº)

# ============= Prompt æ¨¡æ¿ =============

# ç³»ç»Ÿæç¤º - ä»‹ç»ä»»åŠ¡å’Œå¯ç”¨åŠ¨ä½œ
SYSTEM_PROMPT = """You are an intelligent agent operating in a text-based household environment. Your goal is to complete household tasks by interacting with objects in the environment.

Available actions:
- look: look around your current location
- inventory: check what you're carrying
- go to [receptacle]: move to a receptacle (e.g., "go to dresser 1", "go to fridge 1")
- open [receptacle]: open a receptacle (e.g., "open drawer 1")
- close [receptacle]: close a receptacle
- take [object] from [receptacle]: pick up an object (e.g., "take apple 1 from countertop 1")
- move [object] to [receptacle]: put an object down (e.g., "move apple 1 to fridge 1")
- examine [something]: examine an object or receptacle
- use [object]: turn on/off an object (e.g., "use desklamp 1")
- heat [object] with [receptacle]: heat an object using microwave
- clean [object] with [receptacle]: clean an object using sink
- cool [object] with [receptacle]: cool an object using fridge

You must respond in the following format:
THINK: [Your reasoning about what to do next based on the current observation]
ACTION: [The exact action to take, must be one of the available actions]

Only output one action at a time. Do NOT add any other text after the ACTION line."""

# åˆå§‹ä»»åŠ¡æç¤ºæ¨¡æ¿
TASK_PROMPT_TEMPLATE = """=== NEW TASK ===
{observation}

Remember to think step by step and output your response in the format:
THINK: [your reasoning]
ACTION: [your action]"""

# æ¯æ­¥äº¤äº’çš„æç¤ºæ¨¡æ¿
STEP_PROMPT_TEMPLATE = """=== STEP RESULT ===
Your action: {action}
Observation: {observation}

What's your next action?
THINK: [your reasoning]
ACTION: [your action]"""

# Few-shot ç¤ºä¾‹ (å¯é€‰ï¼Œå¸®åŠ©æ¨¡å‹ç†è§£ä»»åŠ¡æ ¼å¼)
FEW_SHOT_EXAMPLES = """
Here are some examples of how to complete tasks:

Example 1 - Put object task:
Task: put some book on desk
THINK: I need to find a book first. Let me look around to see what's available.
ACTION: look

Observation: You are in the middle of a room. Looking quickly around you, you see a bed 1, a desk 1, a drawer 1, a shelf 1.
THINK: I see there's a bed and desk. Books are often on shelves or beds. Let me check the bed first.
ACTION: go to bed 1

Observation: On the bed 1, you see a book 1, a pillow 1.
THINK: I found a book on the bed. Let me take it.
ACTION: take book 1 from bed 1

Observation: You pick up the book 1 from the bed 1.
THINK: Now I have the book. I need to put it on the desk. Let me go there.
ACTION: go to desk 1

Observation: On the desk 1, you see a lamp 1, a pencil 1.
THINK: I'm at the desk now. Let me put the book here to complete the task.
ACTION: move book 1 to desk 1

Observation: You move the book 1 to the desk 1.
Task completed!

Example 2 - Examine in light task:
Task: examine cd under the desklamp
THINK: I need to find a CD and then examine it under a desklamp. First, let me look around.
ACTION: look

Observation: You see a desk 1, a drawer 1, a sidetable 1.
THINK: Let me check the desk for the CD.
ACTION: go to desk 1

Observation: On the desk 1, you see a cd 1, a desklamp 1.
THINK: I found both the CD and desklamp. Let me take the CD first.
ACTION: take cd 1 from desk 1

Observation: You pick up the cd 1 from the desk 1.
THINK: Now I need to turn on the desklamp to examine the CD.
ACTION: use desklamp 1

Observation: You turn on the desklamp 1.
Task completed!

Now complete the following task:
"""


def load_game_files(data_path: str, split: str = "valid_seen", task_types: List[int] = None, max_games: int = -1, seed: int = None) -> List[str]:
    """åŠ è½½æ¸¸æˆæ–‡ä»¶åˆ—è¡¨

    Args:
        data_path: æ•°æ®ç›®å½•è·¯å¾„
        split: æ•°æ®é›†åˆ’åˆ† (train/valid_seen/valid_unseen)
        task_types: ä»»åŠ¡ç±»å‹IDåˆ—è¡¨
        max_games: æœ€å¤§æ¸¸æˆæ•°é‡
        seed: éšæœºç§å­ (ç”¨äºå¯å¤ç°çš„æ¸¸æˆé€‰æ‹©)
    """
    from tqdm import tqdm

    TASK_TYPE_MAP = {
        1: "pick_and_place_simple",
        2: "look_at_obj_in_light",
        3: "pick_clean_then_place_in_recep",
        4: "pick_heat_then_place_in_recep",
        5: "pick_cool_then_place_in_recep",
        6: "pick_two_obj_and_place"
    }

    if task_types is None:
        task_types = [1, 2, 3, 4, 5, 6]

    task_type_names = [TASK_TYPE_MAP[t]
                       for t in task_types if t in TASK_TYPE_MAP]

    split_path = os.path.join(data_path, "json_2.1.1", split)
    game_files = []

    print(f"æ­£åœ¨ä» {split_path} åŠ è½½æ¸¸æˆæ–‡ä»¶...")

    for root, dirs, files in os.walk(split_path):
        if 'game.tw-pddl' in files:
            # æ£€æŸ¥ä»»åŠ¡ç±»å‹
            traj_path = os.path.join(root, 'traj_data.json')
            if os.path.exists(traj_path):
                with open(traj_path, 'r') as f:
                    traj_data = json.load(f)

                if traj_data['task_type'] in task_type_names:
                    game_file = os.path.join(root, 'game.tw-pddl')

                    # æ£€æŸ¥æ˜¯å¦å¯è§£
                    with open(game_file, 'r') as f:
                        game_data = json.load(f)

                    if game_data.get('solvable', False):
                        # æ’é™¤movable receptacleä»»åŠ¡
                        if 'movable' not in root and 'Sliced' not in root:
                            game_files.append(game_file)

    # å…ˆæ’åºç¡®ä¿é¡ºåºä¸€è‡´ï¼Œå†ç”¨ç§å­éšæœºæ‰“ä¹±
    game_files.sort()

    if seed is not None:
        rng = random.Random(seed)
        rng.shuffle(game_files)
        print(f"ä½¿ç”¨éšæœºç§å­: {seed} (ç»“æœå¯å¤ç°)")
    else:
        random.shuffle(game_files)
        print("æœªè®¾ç½®éšæœºç§å­ (ç»“æœä¸å¯å¤ç°)")

    if max_games > 0:
        game_files = game_files[:max_games]

    print(f"æ‰¾åˆ° {len(game_files)} ä¸ªå¯ç”¨æ¸¸æˆ")
    return game_files


def create_environment(game_file: str, max_steps: int = 50):
    """åˆ›å»ºå•ä¸ªæ¸¸æˆç¯å¢ƒ"""

    # è®¾ç½®ç¯å¢ƒwrapper
    alfred_demangler = AlfredDemangler(shuffle=False)
    wrappers = [alfred_demangler, AlfredInfos]

    # æ³¨å†Œç¯å¢ƒ
    request_infos = textworld.EnvInfos(
        won=True,
        admissible_commands=True,
        extras=["gamefile"]
    )

    env_id = textworld.gym.register_game(
        game_file,
        request_infos,
        max_episode_steps=max_steps,
        wrappers=wrappers
    )

    env = textworld.gym.make(env_id)
    return env


def parse_llm_response(response: str) -> Tuple[str, str]:
    """è§£æLLMå“åº”ï¼Œæå–æ€è€ƒå’ŒåŠ¨ä½œ"""
    think = ""
    action = ""

    # å¤„ç† /no_think æ ‡è®°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼Œå»é™¤å®ƒï¼‰
    response = response.replace("/no_think", "").strip()

    # å°è¯•è§£æ THINK å’Œ ACTION
    lines = response.strip().split('\n')

    for i, line in enumerate(lines):
        line_stripped = line.strip()

        # è§£æ THINK
        if line_stripped.upper().startswith('THINK:'):
            think = line_stripped[6:].strip()
        elif line_stripped.upper().startswith('THINK '):
            think = line_stripped[6:].strip()

        # è§£æ ACTION
        if line_stripped.upper().startswith('ACTION:'):
            action = line_stripped[7:].strip()
            break
        elif line_stripped.upper().startswith('ACTION '):
            action = line_stripped[7:].strip()
            break

    # å¦‚æœæ²¡æ‰¾åˆ°æ˜ç¡®çš„ACTIONæ ‡ç­¾ï¼Œå°è¯•æå–æœ€åä¸€è¡Œä½œä¸ºåŠ¨ä½œ
    if not action:
        for line in reversed(lines):
            line = line.strip()
            if line and not line.upper().startswith('THINK'):
                action = line
                break

    # æ¸…ç†actionä¸­å¯èƒ½çš„å¼•å·
    action = action.strip('"\'')

    return think, action


def run_episode(env, model: str, use_few_shot: bool = True, verbose: bool = True) -> Dict:
    """è¿è¡Œå•ä¸ªepisodeï¼Œä½¿ç”¨LLMä½œä¸ºagent"""

    # é‡ç½®ç¯å¢ƒ
    obs, info = env.reset()

    # æ„å»ºå†å²è®°å½•
    conversation_history = []
    actions_taken = []
    observations = [obs]

    done = False
    step = 0
    total_reward = 0

    # æ„å»ºåˆå§‹prompt
    if use_few_shot:
        initial_prompt = FEW_SHOT_EXAMPLES + \
            "\n" + TASK_PROMPT_TEMPLATE.format(observation=obs)
    else:
        initial_prompt = TASK_PROMPT_TEMPLATE.format(observation=obs)

    if verbose:
        print("\n" + "="*60)
        print("åˆå§‹è§‚å¯Ÿ:")
        print(obs)
        print("="*60)

    while not done and step < MAX_STEPS:
        step += 1

        # æ„å»ºå½“å‰prompt
        if step == 1:
            current_prompt = initial_prompt
        else:
            current_prompt = initial_prompt + "\n\n" + \
                "\n\n".join(conversation_history)

        # è°ƒç”¨LLM (ç³»ç»Ÿæç¤ºè¯é€šè¿‡ system_prompt å‚æ•°ä¼ é€’)
        try:
            response = call_openrouter_llm_with_retry(
                current_prompt,
                model=model,
                stream=False,
                temperature=TEMPERATURE,
                max_tokens=512,
                system_prompt=SYSTEM_PROMPT
            )
        except Exception as e:
            print(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            break

        # è§£æå“åº”
        think, action = parse_llm_response(response)

        if verbose:
            print(f"\n--- Step {step} ---")
            print(f"LLM Think: {think}")
            print(f"LLM Action: {action}")

        if not action:
            if verbose:
                print("è­¦å‘Š: æ— æ³•è§£ææœ‰æ•ˆçš„åŠ¨ä½œ")
            action = "look"  # é»˜è®¤åŠ¨ä½œ

        # æ£€æŸ¥åŠ¨ä½œæ˜¯å¦åœ¨å¯ç”¨å‘½ä»¤ä¸­
        admissible = info.get('admissible_commands', [])
        if action not in admissible and admissible:
            # å°è¯•æ¨¡ç³ŠåŒ¹é…
            matched = False
            action_lower = action.lower()
            for cmd in admissible:
                if action_lower == cmd.lower():
                    action = cmd
                    matched = True
                    break

            if not matched and verbose:
                print(f"æ³¨æ„: åŠ¨ä½œ '{action}' ä¸åœ¨å¯ç”¨å‘½ä»¤ä¸­")
                print(f"å¯ç”¨å‘½ä»¤: {admissible[:10]}..." if len(
                    admissible) > 10 else f"å¯ç”¨å‘½ä»¤: {admissible}")

        # æ‰§è¡ŒåŠ¨ä½œ
        obs, reward, done, info = env.step(action)
        total_reward += reward

        actions_taken.append(action)
        observations.append(obs)

        if verbose:
            print(f"ç¯å¢ƒå“åº”: {obs[:200]}..." if len(
                obs) > 200 else f"ç¯å¢ƒå“åº”: {obs}")

        # æ›´æ–°å¯¹è¯å†å²
        step_record = STEP_PROMPT_TEMPLATE.format(
            action=action, observation=obs)
        conversation_history.append(
            f"THINK: {think}\nACTION: {action}\n{step_record}")

        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if info.get('won', False):
            if verbose:
                print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆ! æ­¥æ•°: {step}")
            break
        elif done:
            # done=True ä½† won=False è¡¨ç¤ºè¶…æ—¶æˆ–å…¶ä»–åŸå› ç»“æŸ
            if verbose:
                print(f"\nâ±ï¸ ç¯å¢ƒç»“æŸ (æœªå®Œæˆä»»åŠ¡), æ­¥æ•°: {step}")
            break

    # å¾ªç¯å› è¾¾åˆ° MAX_STEPS è‡ªç„¶ç»“æŸ
    else:
        if verbose and not info.get('won', False):
            print(f"\nâ±ï¸ è¾¾åˆ°æœ€å¤§æ­¥æ•°é™åˆ¶ ({MAX_STEPS}æ­¥), ä»»åŠ¡æœªå®Œæˆ")

    return {
        "success": info.get('won', False),  # åªæœ‰ won=True æ‰ç®—æˆåŠŸ
        "steps": step,
        "actions": actions_taken,
        "observations": observations,
        "reward": total_reward
    }


def run_benchmark(
    model: str = DEFAULT_MODEL,
    num_games: int = NUM_GAMES,
    task_types: List[int] = None,
    use_few_shot: bool = True,
    verbose: bool = True,
    output_file: str = None,
    seed: int = DEFAULT_SEED
):
    """è¿è¡ŒALFWorldåŸºå‡†æµ‹è¯•"""

    data_path = os.environ.get("ALFWORLD_DATA")

    print(f"\n{'='*60}")
    print(f"ALFWorld LLM Agent æµ‹è¯•")
    print(f"{'='*60}")
    print(f"æ¨¡å‹: {model}")
    print(f"æ¸¸æˆæ•°é‡: {num_games}")
    print(f"ä»»åŠ¡ç±»å‹: {task_types if task_types else 'all'}")
    print(f"ä½¿ç”¨Few-shot: {use_few_shot}")
    print(f"éšæœºç§å­: {seed if seed is not None else 'éšæœº'}")
    print(f"æ•°æ®è·¯å¾„: {data_path}")
    print(f"{'='*60}\n")

    # åŠ è½½æ¸¸æˆæ–‡ä»¶
    game_files = load_game_files(
        data_path,
        split="valid_seen",
        task_types=task_types,
        max_games=num_games,
        seed=seed
    )

    if not game_files:
        print("é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¸¸æˆæ–‡ä»¶!")
        return

    # è¿è¡Œæµ‹è¯•
    results = []
    successes = 0
    total_steps = 0

    for i, game_file in enumerate(game_files):
        print(f"\n{'='*60}")
        print(f"æ¸¸æˆ {i+1}/{len(game_files)}")
        print(f"æ–‡ä»¶: {os.path.basename(os.path.dirname(game_file))}")
        print(f"{'='*60}")

        try:
            env = create_environment(game_file, max_steps=MAX_STEPS)
            result = run_episode(
                env, model, use_few_shot=use_few_shot, verbose=verbose)
            env.close()

            result['game_file'] = game_file
            results.append(result)

            if result['success']:
                successes += 1
            total_steps += result['steps']

            print(
                f"\nç»“æœ: {'âœ… æˆåŠŸ' if result['success'] else 'âŒ å¤±è´¥'} (æ­¥æ•°: {result['steps']})")

        except Exception as e:
            print(f"æ¸¸æˆè¿è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            results.append({
                "success": False,
                "steps": 0,
                "error": str(e),
                "game_file": game_file
            })

    # ç»Ÿè®¡ç»“æœ
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•ç»“æœæ±‡æ€»")
    print(f"{'='*60}")
    print(f"æ¨¡å‹: {model}")
    print(f"æ€»æ¸¸æˆæ•°: {len(game_files)}")
    print(f"æˆåŠŸæ•°: {successes}")
    print(f"æˆåŠŸç‡: {successes/len(game_files)*100:.1f}%")
    print(f"å¹³å‡æ­¥æ•°: {total_steps/len(game_files):.1f}")
    print(f"{'='*60}")

    # ä¿å­˜ç»“æœ
    if output_file:
        summary = {
            "model": model,
            "timestamp": datetime.now().isoformat(),
            "config": {
                "num_games": num_games,
                "task_types": task_types,
                "use_few_shot": use_few_shot,
                "max_steps": MAX_STEPS,
                "temperature": TEMPERATURE,
                "seed": seed
            },
            "summary": {
                "total_games": len(game_files),
                "successes": successes,
                "success_rate": successes/len(game_files),
                "avg_steps": total_steps/len(game_files)
            },
            "results": results
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    return results


def demo_single_game(model: str = DEFAULT_MODEL, game_idx: int = 0, seed: int = DEFAULT_SEED):
    """è¿è¡Œå•ä¸ªæ¸¸æˆçš„æ¼”ç¤º"""

    data_path = os.environ.get("ALFWORLD_DATA")

    # åŠ è½½æ¸¸æˆ (ä½¿ç”¨ç§å­ç¡®ä¿å¯å¤ç°)
    game_files = load_game_files(
        data_path, split="valid_seen", max_games=100, seed=seed)

    if game_idx >= len(game_files):
        print(f"æ¸¸æˆç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œåªæœ‰ {len(game_files)} ä¸ªæ¸¸æˆ")
        return

    game_file = game_files[game_idx]

    print(f"\nè¿è¡Œæ¼”ç¤ºæ¸¸æˆ: {os.path.basename(os.path.dirname(game_file))}")

    env = create_environment(game_file, max_steps=MAX_STEPS)
    result = run_episode(env, model, use_few_shot=True, verbose=True)
    env.close()

    return result


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="ALFWorld LLM Agent æµ‹è¯•")
    parser.add_argument("--model", type=str,
                        default=DEFAULT_MODEL, help="LLMæ¨¡å‹åç§°")
    parser.add_argument("--num_games", type=int,
                        default=NUM_GAMES, help="æµ‹è¯•çš„æ¸¸æˆæ•°é‡")
    parser.add_argument("--task_types", type=int, nargs="+", default=None,
                        help="ä»»åŠ¡ç±»å‹ (1-6)")
    parser.add_argument(
        "--no_few_shot", action="store_true", help="ä¸ä½¿ç”¨few-shotç¤ºä¾‹")
    parser.add_argument("--quiet", action="store_true", help="å‡å°‘è¾“å‡º")
    parser.add_argument("--output", type=str, default=None, help="ç»“æœè¾“å‡ºæ–‡ä»¶")
    parser.add_argument("--demo", action="store_true", help="è¿è¡Œå•ä¸ªæ¸¸æˆæ¼”ç¤º")
    parser.add_argument("--game_idx", type=int, default=0, help="æ¼”ç¤ºæ¸¸æˆçš„ç´¢å¼•")
    parser.add_argument("--seed", type=int, default=DEFAULT_SEED,
                        help="éšæœºç§å­ (ç”¨äºå¯å¤ç°çš„æ¸¸æˆé€‰æ‹©ï¼Œé»˜è®¤42)")
    parser.add_argument("--no_seed", action="store_true",
                        help="ä¸ä½¿ç”¨å›ºå®šç§å­ (å®Œå…¨éšæœºé€‰æ‹©æ¸¸æˆ)")

    args = parser.parse_args()

    # å¤„ç†ç§å­å‚æ•°
    seed = None if args.no_seed else args.seed

    if args.demo:
        demo_single_game(model=args.model, game_idx=args.game_idx, seed=seed)
    else:
        # é»˜è®¤è¾“å‡ºæ–‡ä»¶å
        if args.output is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            model_name = args.model.replace("/", "_")
            args.output = f"/home/bmt/evo/bench/alfworld_results_{model_name}_{timestamp}.json"

        run_benchmark(
            model=args.model,
            num_games=args.num_games,
            task_types=args.task_types,
            use_few_shot=not args.no_few_shot,
            verbose=not args.quiet,
            output_file=args.output,
            seed=seed
        )

# ğŸ® è¿è¡Œå•ä¸ªæ¸¸æˆæ¼”ç¤º
# python3 alfworld_test.py --demo --model "qwen/qwen-2.5-7b-instruct"

# ğŸ“Š è¿è¡Œå®Œæ•´æµ‹è¯• (5ä¸ªæ¸¸æˆ)
# python3 alfworld_test.py --model "qwen/qwen3-8b" --num_games 5

# ğŸ¯ æµ‹è¯•ç‰¹å®šä»»åŠ¡ç±»å‹
# python3 alfworld_test.py --model "qwen/qwen3-8b" --task_types 1 2 --num_games 3

# ğŸ”‡ å®‰é™æ¨¡å¼ (å‡å°‘è¾“å‡º)
# python3 alfworld_test.py --model "qwen/qwen3-8b" --num_games 10 --quiet
