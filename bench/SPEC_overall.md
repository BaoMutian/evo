## 1. 项目背景与目标 (Project Overview)

**简单来说，这是一个会“记笔记”并“自我进化”的AI智能体。**

传统的AI Agent在做任务时，往往做完就忘了，下次遇到类似的坑还会再跳。本项目要构建的Agent具有一个**推理记忆库（ReasoningBank）**。它的工作流程如下：

1. **做题/做任务**：尝试解决一个问题。
2. **复盘**：无论成功还是失败，它都会自我反思。“我为什么成功了？用了什么技巧？”或者“我为什么失败了？哪里想错了？”
3. **存入记忆**：将这些“技巧”和“避坑指南”提炼成通用的经验，存入数据库。
4. **再战**：当遇到新问题时，先去数据库里检索有没有相似任务的经验，把这些经验作为“锦囊妙计”写在提示词里，辅助自己更好地解决新问题。

**项目目标：**  
构建一套完整的框架，支持该Agent在**单轮问答**（如数学题）和**多轮交互**（如文字游戏）两种场景下运行，并通过不断的“尝试-总结-应用”循环，实现能力的自我提升。

## 2. 系统配置与环境需求 (System Configuration)

### 2.1 LLM 服务接入

项目**核心不包含本地大模型加载**，所有智能能力必须通过统一的 API 接口获取。

+ **接口标准**：OpenAI SDK 兼容格式（`v1/chat/completions`）。
+ **配置项**：
  - `API_BASE`: API 服务地址（例如 VLLM 的地址 `http://localhost:8000/v1` 或 OpenRouter 地址）。
  - `API_KEY`: 认证密钥。
  - `MODEL_NAME`: 调用的模型名称（如 `gpt-4o-mini`, `deepseek-v3`, `qwen-2.5-72b-instruct` 等）。
+ **并发控制**：需支持异步调用（AsyncIO），以便进行后续的并行测试（MaTTS）。

### 2.2 存储服务

+ **向量数据库**：用于存储和检索记忆（轻量实现，本地jsonl文件存储即可）。
+ **Embedding**：需要接入一个 Embedding 嵌入模型（sentence-transformer）将文本转化为向量。

## 3. 核心功能模块 (Core Functional Modules)

### 3.1 环境适配器 (Environment Adapters)

系统需要能够跑两类不同的测试集，因此需要一个统一的**抽象层**。

+ **适配场景**：
  1. **单轮推理 (Static Benchmarks)**：
     * 如 **MATH, GSM8K, GPQA**。
     * 环境逻辑：输入是题目，输出是答案。Agent 只有一次（或几次CoT步骤）机会，生成的答案与标准答案比对即为结束。
  2. **多轮交互 (Interactive Environments)**：
     * 如 **Alfworld, ScienceWorld**。
     * 环境逻辑：Agent 发送指令（如 `go north`），环境返回状态描述。需要多步操作才能完成任务。

### 3.2 记忆库管理 (Memory Manager)

这是项目的核心组件，负责管理“经验”。

+ **数据结构**：
  - 见详细SPECIFICATION文档
+ **功能需求**：
  - **Retrieve (检索)**：当新任务来时，将新任务转为向量，在库中找到最相似的 Top-K 个历史任务对应的经验。
  - **Add (写入)**：将新提炼出的经验存入库中。不需要复杂的更新逻辑，只管追加（Append-only）。

### 3.3 智能体工作流 (Agent Workflow)

Agent 需要支持带有“锦囊妙计”的思考模式。

+ **Prompt 构造**：
  - 在系统提示词（System Prompt）中预留位置。
  - 逻辑：如果检索到了相关记忆，显示类似于：“以下是过往类似任务的经验教训：[经验内容]”；如果没有，则不显示。
+ **执行模式**：
  - **ReAct**：强制要求模型在输出最终答案或动作前，先输出 `Thought`（思考过程），以便后续提取经验。

### 3.4 裁判与提炼器 (Judge & Extractor)

负责“复盘”和“记笔记”。

+ **Judge (裁判)**：
  - 判断任务是否成功。对于数学题，对比答案；对于交互环境，检查环境返回的 Success 标志。
  - _进阶需求_：如果环境没有给出明确成功信号，需要调用 LLM 进行自我评判（LLM-as-a-Judge）。
+ **Extractor (提炼器)**：
  - 调用 LLM 分析刚刚的轨迹（Query + Thought + Action + Result）。
  - **若成功**：提取“通用策略”（General Strategy）。提示词意图：“你做对了，请总结一个通用的解题公式或原则，不要包含具体数字。”
  - **若失败**：提取“反事实教训”（Counterfactual Lesson）。提示词意图：“你做错了，请反思哪一步想错了，并总结以后遇到类似情况通过什么特征来避免。”

### 3.5 MaTTS 扩展模块 (Memory-aware Test-Time Scaling)

这是“高级进化”功能，通过增加计算量来获取更高质量的记忆。

+ **并行扩展 (Parallel Scaling)**：
  - 针对同一个问题，并发启动 N 个 Agent 进行尝试（设置较高的 Temperature 以增加多样性）。
  - **对比提取**：将这 N 条轨迹（有的成功有的失败）一起发给 LLM。提示词意图：“对比这些做法，找出为什么有的赢了有的输了，提炼出最关键的胜负手。”
+ **串行扩展 (Sequential Scaling)**：
  - 做完题后，强制 Agent 进入“检查模式”。
  - **修正提取**：如果 Agent 在检查过程中自己发现了错误并改对了，捕捉这个“修正瞬间”，提炼成“自我纠错经验”。

## 4. 业务流程描述 (Workflow Description)

开发时请遵循以下主循环逻辑：

1. **初始化**：加载数据集，初始化空的记忆库。
2. **读取任务**：从 Benchmark 获取下一个问题/环境。
3. **检索**：用当前问题去记忆库检索 Top-K 经验。
4. **执行**：
   - Agent 结合检索到的经验，生成推理轨迹和动作。
   - 环境返回结果。
5. **评估**：判断任务成功/失败。
6. **学习 (提炼 & 存储)**：
   - 根据成功/失败状态，调用 Extractor 总结经验。
   - 将新经验写入记忆库。
7. **循环**：进入下一个任务。此时记忆库已变大，Agent 变强了。

## 5. 交互与输出规范

+ **日志记录**：详细记录每一步的 `Retrieval Result`（检索到了啥）、`Thought`（想了啥）、`Action`（做了啥）以及 `Extracted Memory`（学到了啥）。
+ **数据持久化**：记忆库需要能保存到磁盘（如 JSON 文件），支持断点续传。